<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Comfyui on 龙舌兰日落AgaveSunset</title>
        <link>https://agavesunset.github.io/categories/comfyui/</link>
        <description>Recent content in Comfyui on 龙舌兰日落AgaveSunset</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>zh-cn</language>
        <copyright>agavesunset</copyright>
        <lastBuildDate>Sun, 06 Jul 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://agavesunset.github.io/categories/comfyui/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>印花提取重绘量产的混合架构</title>
        <link>https://agavesunset.github.io/p/%E5%8D%B0%E8%8A%B1%E6%8F%90%E5%8F%96%E9%87%8D%E7%BB%98%E9%87%8F%E4%BA%A7%E7%9A%84%E6%B7%B7%E5%90%88%E6%9E%B6%E6%9E%84/</link>
        <pubDate>Sun, 06 Jul 2025 00:00:00 +0000</pubDate>
        
        <guid>https://agavesunset.github.io/p/%E5%8D%B0%E8%8A%B1%E6%8F%90%E5%8F%96%E9%87%8D%E7%BB%98%E9%87%8F%E4%BA%A7%E7%9A%84%E6%B7%B7%E5%90%88%E6%9E%B6%E6%9E%84/</guid>
        <description>&lt;h2 id=&#34;实现的效果遇到的问题难点解决思路细节&#34;&gt;实现的效果，遇到的问题，难点，解决思路，细节
&lt;/h2&gt;&lt;p&gt;内容：
训练模型：使用了40组抱枕在不同场景的图片，设立R_T图，采用小志的t2itraniner训练器，来减少图片的拉升效果，大约运行两千八百步，还需要进一步提升
使用仙云宫48gb显卡训练，耗资50，
在解决了模型训练的问题之后下一步就是电脑性能，当前的设备是4070s，只有12gb，无法载入完整的模型得到更好的效果，nunchaku又不与lora兼容，
fp8模型的效果很惨，怀疑是架构选择问题，因此需要额外的方式，选择了云平台来分担性能缺失，如果是云平台的话就会出现图片传递的问题，把运行集成在一个界面是最方便的，
最终使用了rh平台的api调用，经过提取的图片传递到了本地部署的工作流中，图片再一次传入另外一个工作流api进行反推，将反推的值和图片都传入本地部署中，进行带有描述的重绘
为了保证质量和提高细节的情况下需要进行多次采样，（可以参考wan2.2的专家模型思路，高噪声的情况下使用构图模型，低噪声的情况下使用细节模型），在传统的ksampler采样器中
是默认开启了噪声注入的，因此细节会更加丰富，第一次采样需要使用较高的去噪，来尽可能的发挥模型的能力，第二次采用使用一个较低的去噪强度来修复掉图片中错误的一些纹理，这两次运行都需要使用1024
分辨率大小的图片来贴合模型最佳尺寸，现在我们得到了还行的图片，下一步就是对图片的放大通过计算，假如需要300ppi的话并且55cm的话px需要达到6k，这种放大方式尺度很大，需要采用注入细节的方式，
即ttp分图加上一个采样&lt;/p&gt;
&lt;h2 id=&#34;其他文档预写入&#34;&gt;其他文档预写入
&lt;/h2&gt;&lt;p&gt;nanobanana使用缺陷，需要参考，不稳定，抽卡&lt;/p&gt;
</description>
        </item>
        
    </channel>
</rss>
